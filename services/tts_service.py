#!/usr/bin/env python3
"""
TTSæœåŠ¡æ ¸å¿ƒé€»è¾‘
"""
import asyncio
import hashlib
import os
import shutil
import time
import uuid
from typing import List, Dict, Any, Tuple, Optional
from concurrent.futures import ThreadPoolExecutor

from config import TTS_CONFIG, AZURE_CONFIG, EDGE_CONFIG
from engines import TTSEngineManager, AzureTTSEngine, EdgeTTSEngine
from utils.cache import TTSCache
from utils.audio import AudioProcessor
from utils.decorators import async_retry


class TTSService:
    """TTSæœåŠ¡ç±»ï¼Œç»Ÿä¸€ç®¡ç†ä¸åŒçš„TTSå¼•æ“"""
    
    def __init__(self):
        self.engine_manager = TTSEngineManager()
        self.cache = TTSCache(TTS_CONFIG['cache_dir'])
        self.audio_processor = AudioProcessor()
        self._semaphores = {}
        
        # åˆå§‹åŒ–å¼•æ“
        self._initialize_engines()
        
    def _initialize_engines(self):
        """åˆå§‹åŒ–æ‰€æœ‰TTSå¼•æ“"""
        try:
            # åˆå§‹åŒ–Azure TTSå¼•æ“
            azure_engine = AzureTTSEngine(AZURE_CONFIG)
            self.engine_manager.register_engine('azure', azure_engine)
            print("ğŸ”µ Azure TTSå¼•æ“æ³¨å†ŒæˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸  Azure TTSå¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
        
        try:
            # åˆå§‹åŒ–Edge TTSå¼•æ“
            edge_engine = EdgeTTSEngine(EDGE_CONFIG)
            self.engine_manager.register_engine('edge', edge_engine)
            print("ğŸŸ¢ Edge TTSå¼•æ“æ³¨å†ŒæˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸  Edge TTSå¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # è®¾ç½®é»˜è®¤å¼•æ“
        default_engine = TTS_CONFIG['default_engine']
        if not self.engine_manager.set_current_engine(default_engine):
            # å¦‚æœé»˜è®¤å¼•æ“ä¸å¯ç”¨ï¼Œå°è¯•å…¶ä»–å¼•æ“
            available_engines = self.engine_manager.get_available_engines()
            if available_engines:
                fallback_engine = available_engines[0]
                self.engine_manager.set_current_engine(fallback_engine)
                print(f"âš¡ é»˜è®¤å¼•æ“ {default_engine} ä¸å¯ç”¨ï¼Œåˆ‡æ¢åˆ° {fallback_engine}")
            else:
                raise RuntimeError("æ²¡æœ‰å¯ç”¨çš„TTSå¼•æ“")
    
    def get_semaphore(self, max_concurrent=None):
        """è·å–å½“å‰äº‹ä»¶å¾ªç¯çš„Semaphore"""
        try:
            loop = asyncio.get_running_loop()
            loop_id = id(loop)
            
            if max_concurrent and max_concurrent != TTS_CONFIG['max_concurrent_tasks']:
                return asyncio.Semaphore(max_concurrent)
            
            if loop_id not in self._semaphores:
                self._semaphores[loop_id] = asyncio.Semaphore(TTS_CONFIG['max_concurrent_tasks'])
            
            return self._semaphores[loop_id]
        except RuntimeError:
            concurrent_limit = max_concurrent if max_concurrent else TTS_CONFIG['max_concurrent_tasks']
            return asyncio.Semaphore(concurrent_limit)
    
    async def get_voices(self) -> Dict[str, List[Dict[str, Any]]]:
        """è·å–å¯ç”¨è¯­éŸ³åˆ—è¡¨"""
        current_engine = self.engine_manager.get_current_engine()
        if not current_engine:
            return {}
        
        try:
            voices = await current_engine.get_voices()
            if voices:
                return current_engine.group_voices_by_language(voices)
            else:
                # å¦‚æœè·å–å¤±è´¥ï¼Œå°è¯•æ•…éšœè½¬ç§»
                if await self.engine_manager.fallback_to_next_engine():
                    current_engine = self.engine_manager.get_current_engine()
                    voices = await current_engine.get_voices()
                    return current_engine.group_voices_by_language(voices)
                else:
                    # è¿”å›å¤‡ç”¨è¯­éŸ³åˆ—è¡¨
                    return current_engine.get_fallback_voices()
        except Exception as e:
            print(f"âŒ è·å–è¯­éŸ³åˆ—è¡¨å¤±è´¥: {e}")
            # è¿”å›å¤‡ç”¨è¯­éŸ³åˆ—è¡¨
            current_engine = self.engine_manager.get_current_engine()
            if current_engine:
                return current_engine.get_fallback_voices()
            return {}
    
    @async_retry(retries=3, delay=2)
    async def synthesize_single(self, text: str, output_path: str, voice: str, 
                               rate: str, volume: str, pitch: str, 
                               max_concurrent=None, audio_format="mp3") -> bool:
        """åˆæˆå•ä¸ªTTSéŸ³é¢‘"""
        async with self.get_semaphore(max_concurrent):
            # æ£€æŸ¥ç¼“å­˜
            cache_key = self.cache.get_cache_key(text, voice, rate, volume, pitch, audio_format)
            
            if await self.cache.copy_from_cache(cache_key, output_path):
                return True
            
            print(f"ç¼“å­˜æœªå‘½ä¸­ï¼Œç”Ÿæˆæ–°æ–‡ä»¶: {text[:30]}... (æ ¼å¼: {audio_format})")
            
            # ä½¿ç”¨å½“å‰å¼•æ“åˆæˆ
            current_engine = self.engine_manager.get_current_engine()
            if not current_engine:
                raise RuntimeError("æ²¡æœ‰å¯ç”¨çš„TTSå¼•æ“")
            
            try:
                success = await current_engine.synthesize_to_file(
                    text, output_path, voice, 
                    rate=rate, volume=volume, pitch=pitch, audio_format=audio_format
                )
                
                if success:
                    # ä¿å­˜åˆ°ç¼“å­˜
                    await self.cache.save_to_cache(cache_key, output_path)
                    return True
                else:
                    raise Exception("TTSåˆæˆå¤±è´¥")
                    
            except Exception as e:
                print(f"âŒ ä½¿ç”¨å½“å‰å¼•æ“åˆæˆå¤±è´¥: {e}")
                
                # å°è¯•æ•…éšœè½¬ç§»
                if await self.engine_manager.fallback_to_next_engine():
                    print("ğŸ”„ å°è¯•ä½¿ç”¨å¤‡ç”¨å¼•æ“...")
                    fallback_engine = self.engine_manager.get_current_engine()
                    success = await fallback_engine.synthesize_to_file(
                        text, output_path, voice,
                        rate=rate, volume=volume, pitch=pitch, audio_format=audio_format
                    )
                    
                    if success:
                        await self.cache.save_to_cache(cache_key, output_path)
                        return True
                
                raise e
    
    async def batch_synthesize_concurrent(self, items: List[Dict], rate: str, volume: str, 
                                        pitch: str, max_concurrent=None, 
                                        audio_format="mp3") -> List[Tuple[str, Dict]]:
        """æ‰¹é‡å¹¶å‘åˆæˆTTSéŸ³é¢‘"""
        tasks = []
        
        for i, item in enumerate(items):
            text = item.get('text', '').strip()
            if not text:
                continue
            
            voice = item.get('voice', AZURE_CONFIG['default_voice'])
            item_rate = item.get('rate', rate)
            item_volume = item.get('volume', volume)
            item_pitch = item.get('pitch', pitch)
            
            # ç”Ÿæˆä¸´æ—¶æ–‡ä»¶å
            temp_filename = f"batch_{uuid.uuid4()}.{audio_format}"
            temp_path = os.path.join(TTS_CONFIG['cache_dir'], temp_filename)
            
            # åˆ›å»ºå¼‚æ­¥ä»»åŠ¡
            task = self.synthesize_single(text, temp_path, voice, item_rate, 
                                        item_volume, item_pitch, max_concurrent, audio_format)
            tasks.append((task, temp_path, item, i))
        
        print(f"å¼€å§‹æ™ºèƒ½å¹¶å‘ç”Ÿæˆ {len(tasks)} ä¸ªTTSéŸ³é¢‘...")
        
        # å¹¶å‘æ‰§è¡Œ
        results = []
        completed_tasks_results = await asyncio.gather(*[task_info[0] for task_info in tasks], return_exceptions=True)
        
        for i, task_info in enumerate(tasks):
            original_task, temp_path, item_details, original_index = task_info
            result = completed_tasks_results[i]
            
            if isinstance(result, Exception):
                print(f"âŒ ä»»åŠ¡ {original_index + 1} å¤±è´¥: {result}")
                continue
            
            # éªŒè¯æ–‡ä»¶
            if result is True and os.path.exists(temp_path):
                file_size = os.path.getsize(temp_path)
                if file_size > 0:
                    results.append((temp_path, item_details))
                    print(f"âœ… å·²ç”ŸæˆéŸ³é¢‘ {original_index + 1}/{len(tasks)}: {item_details.get('text', '')[:20]}... (å¤§å°: {file_size} bytes)")
                else:
                    print(f"âš ï¸  ä»»åŠ¡ {original_index + 1} ç”Ÿæˆçš„æ–‡ä»¶ä¸ºç©º")
                    try:
                        os.remove(temp_path)
                    except:
                        pass
        
        print(f"ğŸµ å¹¶å‘ç”Ÿæˆå®Œæˆ: æˆåŠŸ {len(results)}/{len(tasks)} ä¸ªéŸ³é¢‘æ–‡ä»¶")
        return results
    
    def _deduplicate_items(self, items: List[Dict]) -> Tuple[List[Dict], Dict[str, List[int]]]:
        """
        å¯¹æ‰¹é‡TTSé¡¹ç›®è¿›è¡Œå»é‡å¤„ç†
        
        Args:
            items: åŸå§‹é¡¹ç›®åˆ—è¡¨
            
        Returns:
            tuple: (å»é‡åçš„é¡¹ç›®åˆ—è¡¨, å»é‡æ˜ å°„è¡¨)
                  å»é‡æ˜ å°„è¡¨æ ¼å¼: {unique_key: [åŸå§‹ç´¢å¼•åˆ—è¡¨]}
        """
        seen_items = {}  # å­˜å‚¨å·²è§è¿‡çš„é¡¹ç›®
        unique_items = []  # å»é‡åçš„å”¯ä¸€é¡¹ç›®
        dedup_map = {}  # æ˜ å°„è¡¨ï¼šunique_key -> åŸå§‹ç´¢å¼•åˆ—è¡¨
        
        for i, item in enumerate(items):
            text = item.get('text', '').strip()
            if not text:
                continue
                
            voice = item.get('voice', AZURE_CONFIG['default_voice'])
            rate = item.get('rate', '+0%')
            volume = item.get('volume', '+0%')
            pitch = item.get('pitch', '+0Hz')
            
            # ç”Ÿæˆå”¯ä¸€æ ‡è¯†é”®
            unique_key = f"{text}|{voice}|{rate}|{volume}|{pitch}"
            
            if unique_key in seen_items:
                # å¦‚æœå·²å­˜åœ¨ï¼Œæ·»åŠ åˆ°æ˜ å°„è¡¨
                dedup_map[unique_key].append(i)
            else:
                # æ–°çš„å”¯ä¸€é¡¹ç›®
                seen_items[unique_key] = len(unique_items)
                unique_items.append(item)
                dedup_map[unique_key] = [i]
        
        original_count = len(items)
        unique_count = len(unique_items)
        duplicate_count = original_count - unique_count
        
        if duplicate_count > 0:
            print(f"ğŸ”„ å†…å®¹å»é‡: åŸå§‹ {original_count} ä¸ªé¡¹ç›® â†’ å»é‡å {unique_count} ä¸ªé¡¹ç›® (å‡å°‘ {duplicate_count} ä¸ªé‡å¤é¡¹ç›®)")
            
            # æ‰“å°å»é‡è¯¦æƒ…
            for unique_key, indices in dedup_map.items():
                if len(indices) > 1:
                    text_preview = unique_key.split('|')[0][:30]
                    print(f"   ğŸ“‹ é‡å¤å†…å®¹: '{text_preview}...' å‡ºç° {len(indices)} æ¬¡ (ä½ç½®: {indices})")
        else:
            print(f"âœ… æ— é‡å¤å†…å®¹: {original_count} ä¸ªé¡¹ç›®å‡ä¸ºå”¯ä¸€")
            
        return unique_items, dedup_map

    def _reconstruct_results_with_dedup(self, unique_results: List[str], 
                                      dedup_map: Dict[str, List[int]], 
                                      unique_items: List[Dict]) -> List[str]:
        """
        æ ¹æ®å»é‡æ˜ å°„è¡¨é‡å»ºå®Œæ•´çš„ç»“æœåˆ—è¡¨
        
        Args:
            unique_results: å»é‡åçš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            dedup_map: å»é‡æ˜ å°„è¡¨
            unique_items: å»é‡åçš„é¡¹ç›®åˆ—è¡¨
            
        Returns:
            å®Œæ•´çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆåŒ…å«é‡å¤é¡¹ç›®çš„å¤åˆ¶ï¼‰
        """
        if not unique_results or not dedup_map:
            return unique_results
            
        full_results = [None] * sum(len(indices) for indices in dedup_map.values())
        
        # ä¸ºæ¯ä¸ªå”¯ä¸€é¡¹ç›®ç”Ÿæˆé”®
        for i, (unique_item, result_path) in enumerate(zip(unique_items, unique_results)):
            text = unique_item.get('text', '').strip()
            voice = unique_item.get('voice', AZURE_CONFIG['default_voice'])
            rate = unique_item.get('rate', '+0%')
            volume = unique_item.get('volume', '+0%')
            pitch = unique_item.get('pitch', '+0Hz')
            
            unique_key = f"{text}|{voice}|{rate}|{volume}|{pitch}"
            
            if unique_key in dedup_map:
                # å¤åˆ¶éŸ³é¢‘æ–‡ä»¶åˆ°æ‰€æœ‰éœ€è¦çš„ä½ç½®
                for original_index in dedup_map[unique_key]:
                    full_results[original_index] = result_path
        
        # è¿‡æ»¤æ‰Noneå€¼ï¼ˆå¯èƒ½æ˜¯ç©ºæ–‡æœ¬é¡¹ç›®ï¼‰
        return [result for result in full_results if result is not None]

    async def create_batch_audio(self, items: List[Dict], output_name: str, 
                               rate: str, volume: str, pitch: str,
                               silence_duration: int = 200, 
                               use_concurrent: bool = True,
                               max_concurrent: Optional[int] = None,
                               audio_format: str = "mp3") -> Dict[str, Any]:
        """æ‰¹é‡åˆ›å»ºéŸ³é¢‘å¹¶åˆå¹¶"""
        start_time = time.time()
        original_items_count = len(items)
        
        # ğŸ”„ å†…å®¹å»é‡å¤„ç†
        unique_items, dedup_map = self._deduplicate_items(items)
        items_count = len(unique_items)
        
        # æ™ºèƒ½é€‰æ‹©å¤„ç†æ¨¡å¼
        if not use_concurrent or items_count <= 3:
            processing_mode = 'serial'
            print(f"ğŸ”„ ä½¿ç”¨ä¸²è¡Œå¤„ç†æ¨¡å¼ (é¡¹ç›®æ•°: {items_count}, æ ¼å¼: {audio_format})")
            temp_files = await self._batch_synthesize_serial(unique_items, rate, volume, pitch, audio_format)
        else:
            processing_mode = 'concurrent'
            concurrent_limit = max_concurrent or TTS_CONFIG['max_concurrent_tasks']
            print(f"âš¡ ä½¿ç”¨æ™ºèƒ½å¹¶å‘å¤„ç†æ¨¡å¼ (é¡¹ç›®æ•°: {items_count}, å¹¶å‘æ•°: {concurrent_limit}, æ ¼å¼: {audio_format})")
            results = await self.batch_synthesize_concurrent(unique_items, rate, volume, pitch, concurrent_limit, audio_format)
            temp_files = [result[0] for result in results]
        
        if not temp_files:
            raise ValueError('æ²¡æœ‰ç”Ÿæˆä»»ä½•éŸ³é¢‘æ–‡ä»¶')
        
        # ğŸ”„ æ ¹æ®å»é‡æ˜ å°„é‡å»ºå®Œæ•´ç»“æœ
        if len(unique_items) < original_items_count:
            print(f"ğŸ”„ é‡å»ºå®Œæ•´éŸ³é¢‘åºåˆ—: {len(temp_files)} ä¸ªå”¯ä¸€æ–‡ä»¶ â†’ {original_items_count} ä¸ªéŸ³é¢‘ç‰‡æ®µ")
            full_temp_files = self._reconstruct_results_with_dedup(temp_files, dedup_map, unique_items)
        else:
            full_temp_files = temp_files
        
        # éªŒè¯æ–‡ä»¶
        validated_files = []
        for temp_file in full_temp_files:
            if os.path.exists(temp_file) and os.path.getsize(temp_file) > 0:
                validated_files.append(temp_file)
        
        if not validated_files:
            raise ValueError('æ²¡æœ‰æœ‰æ•ˆçš„éŸ³é¢‘æ–‡ä»¶å¯åˆå¹¶')
        
        # åˆå¹¶éŸ³é¢‘æ–‡ä»¶
        output_path = os.path.join(TTS_CONFIG['cache_dir'], output_name)
        success = await self.audio_processor.combine_audio_files(
            validated_files, output_path, silence_duration, audio_format
        )
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆåªåˆ é™¤å”¯ä¸€çš„æ–‡ä»¶ï¼Œé¿å…é‡å¤åˆ é™¤ï¼‰
        unique_temp_files = list(set(temp_files))  # å»é™¤é‡å¤çš„æ–‡ä»¶è·¯å¾„
        for temp_file in unique_temp_files:
            try:
                if os.path.exists(temp_file):
                    os.remove(temp_file)
            except:
                pass
        
        generation_time = time.time() - start_time
        
        if not success:
            raise RuntimeError('éŸ³é¢‘åˆå¹¶å¤±è´¥')
        
        duplicate_count = original_items_count - items_count
        efficiency_info = ""
        if duplicate_count > 0:
            efficiency_gain = round((duplicate_count / original_items_count) * 100, 1)
            efficiency_info = f" (å»é‡èŠ‚çœ {duplicate_count} æ¬¡åˆæˆï¼Œæ•ˆç‡æå‡ {efficiency_gain}%)"
        
        return {
            'output_path': output_path,
            'items_processed': original_items_count,  # è¿”å›åŸå§‹é¡¹ç›®æ•°
            'unique_items_synthesized': items_count,   # å®é™…åˆæˆçš„å”¯ä¸€é¡¹ç›®æ•°
            'generation_time': round(generation_time, 2),
            'processing_mode': processing_mode,
            'audio_format': audio_format,
            'efficiency_info': efficiency_info
        }
    
    async def _batch_synthesize_serial(self, items: List[Dict], rate: str, volume: str, 
                                     pitch: str, audio_format: str = "mp3") -> List[str]:
        """ä¸²è¡Œæ‰¹é‡åˆæˆ"""
        temp_files = []
        
        for i, item in enumerate(items):
            text = item.get('text', '')
            voice = item.get('voice', AZURE_CONFIG['default_voice'])
            item_rate = item.get('rate', rate)
            item_volume = item.get('volume', volume)
            item_pitch = item.get('pitch', pitch)
            
            if not text.strip():
                continue
            
            # ç”Ÿæˆä¸´æ—¶æ–‡ä»¶å
            file_ext = audio_format
            temp_filename = f"batch_{uuid.uuid4()}.{file_ext}"
            temp_path = os.path.join(TTS_CONFIG['cache_dir'], temp_filename)
            
            # åˆæˆTTSéŸ³é¢‘
            success = await self.synthesize_single(text, temp_path, voice, item_rate, 
                                                 item_volume, item_pitch, None, audio_format)
            if success:
                temp_files.append(temp_path)
                print(f"å·²ç”ŸæˆéŸ³é¢‘ {i+1}/{len(items)}: {text[:20]}... (æ ¼å¼: {audio_format})")
        
        return temp_files
    
    def get_current_engine_info(self) -> Dict[str, Any]:
        """è·å–å½“å‰å¼•æ“ä¿¡æ¯"""
        current_engine = self.engine_manager.get_current_engine()
        if current_engine:
            return {
                'name': current_engine.name,
                'available_engines': self.engine_manager.get_available_engines(),
                'config': current_engine.config
            }
        return {}
    
    def switch_engine(self, engine_name: str) -> bool:
        """åˆ‡æ¢TTSå¼•æ“"""
        return self.engine_manager.set_current_engine(engine_name)

    async def create_batch_tts_with_timecodes(self, items: List[Dict], 
                                            rate: str, volume: str, pitch: str,
                                            silence_duration_ms: int = 200, 
                                            audio_format: str = "mp3",
                                            use_concurrent: bool = True,
                                            max_concurrent: Optional[int] = None) -> Dict[str, Any]:
        """
        æ‰¹é‡åˆæˆTTSéŸ³é¢‘ï¼Œä¸åˆå¹¶ï¼Œè¿”å›å„ç‰‡æ®µçš„æ—¶é—´ç ä¿¡æ¯ã€‚
        """
        start_time = time.time()
        original_items_count = len(items)
        
        # 1. å†…å®¹å»é‡
        # unique_items: list of unique item dicts
        # dedup_map: dict where key is "text|voice|rate|volume|pitch" and value is list of original indices
        unique_items, dedup_map = self._deduplicate_items(items)
        items_to_synthesize_count = len(unique_items)
        
        print(f"â±ï¸ å¼€å§‹æ‰¹é‡TTSï¼ˆå¸¦æ—¶é—´ç ï¼‰: {original_items_count} ä¸ªåŸå§‹é¡¹ç›®, {items_to_synthesize_count} ä¸ªå”¯ä¸€é¡¹ç›®")

        # 2. åˆæˆå”¯ä¸€çš„éŸ³é¢‘ç‰‡æ®µ
        # synthesized_unique_audios: list of dicts {'path': str, 'item_detail': dict, 'duration': float (initially 0)}
        # This list's order matches the order of unique_items
        synthesized_unique_audios = []

        if items_to_synthesize_count == 0: # å¦‚æœæ²¡æœ‰å”¯ä¸€é¡¹ç›®ï¼ˆä¾‹å¦‚æ‰€æœ‰è¾“å…¥éƒ½æ˜¯ç©ºæ–‡æœ¬ï¼‰
            print("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„å”¯ä¸€é¡¹ç›®è¿›è¡Œåˆæˆã€‚")
        elif not use_concurrent or items_to_synthesize_count <= 3:
            processing_mode = 'serial'
            print(f"ğŸ”„ ä½¿ç”¨ä¸²è¡Œå¤„ç†æ¨¡å¼ (å”¯ä¸€é¡¹ç›®æ•°: {items_to_synthesize_count}, æ ¼å¼: {audio_format})")
            synthesized_paths = await self._batch_synthesize_serial(unique_items, rate, volume, pitch, audio_format)
            for i, path in enumerate(synthesized_paths):
                if path and os.path.exists(path) and os.path.getsize(path) > 0:
                    synthesized_unique_audios.append({'path': path, 'item_detail': unique_items[i], 'duration': 0.0})
                else:
                    print(f"âš ï¸ ä¸²è¡Œåˆæˆçš„éŸ³é¢‘æ— æ•ˆæˆ–ä¸ºç©º: {path} (å¯¹åº”å”¯ä¸€é¡¹ç›®ç´¢å¼• {i})")
                    # æ·»åŠ ä¸€ä¸ªå ä½ç¬¦ï¼Œæˆ–è®°å½•é”™è¯¯ï¼Œä»¥ä¾¿åç»­å¤„ç†
                    synthesized_unique_audios.append({'path': None, 'item_detail': unique_items[i], 'duration': 0.0, 'error': 'synthesis_failed_or_empty'})
        else:
            processing_mode = 'concurrent'
            concurrent_limit = max_concurrent or TTS_CONFIG['max_concurrent_tasks']
            print(f"âš¡ ä½¿ç”¨æ™ºèƒ½å¹¶å‘å¤„ç†æ¨¡å¼ (å”¯ä¸€é¡¹ç›®æ•°: {items_to_synthesize_count}, å¹¶å‘æ•°: {concurrent_limit}, æ ¼å¼: {audio_format})")
            # results: List[Tuple[str, Dict]] -> (temp_path, item_details_from_unique_items)
            # The order of `results` corresponds to the order of `unique_items`
            results = await self.batch_synthesize_concurrent(unique_items, rate, volume, pitch, concurrent_limit, audio_format)
            for i, (path, item_detail) in enumerate(results): # item_detail is from unique_items
                if path and os.path.exists(path) and os.path.getsize(path) > 0:
                    synthesized_unique_audios.append({'path': path, 'item_detail': item_detail, 'duration': 0.0})
                else:
                    print(f"âš ï¸ å¹¶å‘åˆæˆçš„éŸ³é¢‘æ— æ•ˆæˆ–ä¸ºç©º: {path} (å¯¹åº”å”¯ä¸€é¡¹ç›®ç´¢å¼• {i})")
                    synthesized_unique_audios.append({'path': None, 'item_detail': item_detail, 'duration': 0.0, 'error': 'synthesis_failed_or_empty'})
        
        if not synthesized_unique_audios and items_to_synthesize_count > 0 : # å¦‚æœæœ‰å°è¯•åˆæˆä½†åˆ—è¡¨ä¸ºç©º
             raise ValueError('æ‰€æœ‰å”¯ä¸€é¡¹ç›®çš„éŸ³é¢‘åˆæˆå‡å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œæ—¶é—´ç åˆ†æ')
        elif items_to_synthesize_count == 0: # å¦‚æœå¼€å§‹å°±æ²¡æœ‰å”¯ä¸€é¡¹ç›®
            pass # ç»§ç»­æ‰§è¡Œï¼Œå°†è¿”å›ç©ºæ—¶é—´ç ç­‰


        # 3. è·å–æ¯ä¸ªæœ‰æ•ˆå”¯ä¸€éŸ³é¢‘ç‰‡æ®µçš„æ—¶é•¿
        valid_audio_paths_for_duration_analysis = [info['path'] for info in synthesized_unique_audios if info['path']]
        
        if valid_audio_paths_for_duration_analysis:
            print(f"ğŸ” åˆ†æ {len(valid_audio_paths_for_duration_analysis)} ä¸ªå”¯ä¸€éŸ³é¢‘æ–‡ä»¶çš„æ—¶é•¿...")
            durations_sec = await self.audio_processor.get_audio_durations(valid_audio_paths_for_duration_analysis)
            
            # å°†æ—¶é•¿æ›´æ–°å› synthesized_unique_audios
            duration_idx = 0
            for info in synthesized_unique_audios:
                if info['path']: # åªä¸ºæœ‰è·¯å¾„çš„æ–‡ä»¶æ›´æ–°æ—¶é•¿
                    if duration_idx < len(durations_sec):
                        info['duration'] = durations_sec[duration_idx]
                        print(f"   ğŸ“„ éŸ³é¢‘: ...{info['path'][-20:]}, æ—¶é•¿: {info['duration']:.3f}s")
                        duration_idx += 1
                    else: # ä¸åº”å‘ç”Ÿï¼Œå¦‚æœå‘ç”Ÿäº†è¯´æ˜ durations_sec é•¿åº¦ä¸å¤Ÿ
                        print(f"   âš ï¸ è­¦å‘Š: éŸ³é¢‘ {info['path']} æ²¡æœ‰å¯¹åº”çš„æ—¶é•¿ä¿¡æ¯ã€‚")
                        info['duration'] = 0.0 # æˆ–å…¶ä»–é»˜è®¤/é”™è¯¯æ ‡è®°

        # 4. æ ¹æ®å»é‡æ˜ å°„å’Œæ—¶é•¿è®¡ç®—æ—¶é—´ç 
        # `final_timecodes_ordered` will store dicts {text, original_index, start_time_ms, duration_ms, end_time_ms}
        # in the order of the original `items`
        final_timecodes_ordered = [None] * original_items_count
        
        # Create a map from unique_item's key to its info (path, duration)
        # The key must be generated exactly as in _deduplicate_items
        unique_item_key_to_info_map = {}
        for i, unique_item_detail_dict in enumerate(synthesized_unique_audios):
            # unique_item_detail_dict['item_detail'] is the item from unique_items
            # unique_item_detail_dict['duration'] is its calculated duration
            key = self._generate_item_key(unique_item_detail_dict['item_detail'], rate, volume, pitch)
            unique_item_key_to_info_map[key] = {
                'duration': unique_item_detail_dict['duration'], 
                'path': unique_item_detail_dict['path'], # For reference or cleanup
                'synthesized_item': unique_item_detail_dict['item_detail'] # The actual item that was synthesized
            }

        # Iterate through the original items' structure using dedup_map
        for unique_key_from_dedup, original_indices_list in dedup_map.items():
            # Get the synthesized info for this unique_key
            synthesized_info = unique_item_key_to_info_map.get(unique_key_from_dedup)
            
            item_duration_sec = 0.0
            if synthesized_info:
                item_duration_sec = synthesized_info['duration']
            else:
                # This case implies a mismatch or an item that was in dedup_map but not synthesized
                # (e.g., if all items were empty strings, unique_items would be empty)
                # Or, if the key generation had subtle differences.
                # _deduplicate_items filters out empty text items, so unique_items won't contain them.
                # dedup_map's keys are based on non-empty text items.
                print(f"âš ï¸ è­¦å‘Š: åœ¨ 'unique_item_key_to_info_map' ä¸­æœªæ‰¾åˆ°é”® '{unique_key_from_dedup}'ã€‚")
                print(f"    è¿™å¯èƒ½è¡¨ç¤ºè¯¥å”¯ä¸€é¡¹åˆæˆå¤±è´¥æˆ–é”®ç”Ÿæˆä¸ä¸€è‡´ã€‚å—å½±å“çš„åŸå§‹ç´¢å¼•: {original_indices_list}")
                # For items associated with this key, duration will be 0.
            
            item_duration_ms = item_duration_sec * 1000

            for original_idx in original_indices_list:
                original_item_text = items[original_idx].get('text', '')
                # We don't use current_time_ms here yet, will calculate cumulative time later
                timecode_entry = {
                    'text': original_item_text,
                    'original_index': original_idx,
                    'duration_ms': round(item_duration_ms), 
                    'synthesized_text': synthesized_info['synthesized_item'].get('text', '') if synthesized_info and synthesized_info.get('synthesized_item') else original_item_text, # Text actually sent for synthesis
                    'voice_used': synthesized_info['synthesized_item'].get('voice') if synthesized_info and synthesized_info.get('synthesized_item') else items[original_idx].get('voice'),
                }
                final_timecodes_ordered[original_idx] = timecode_entry
        
        # Calculate cumulative start and end times including silence
        actual_timecodes_with_silence = []
        running_time_ms = 0.0
        for i in range(original_items_count):
            entry = final_timecodes_ordered[i]
            if entry: # If it's a valid entry (not None)
                entry['start_time_ms'] = round(running_time_ms)
                entry['end_time_ms'] = round(running_time_ms + entry['duration_ms'])
                actual_timecodes_with_silence.append(entry)
                
                running_time_ms += entry['duration_ms']
                # Add silence if it's not the last actual item that will have audio
                # Check if there's a next valid item to determine if silence is needed
                is_last_valid_item = True
                for k in range(i + 1, original_items_count):
                    if final_timecodes_ordered[k] and final_timecodes_ordered[k]['duration_ms'] > 0:
                        is_last_valid_item = False
                        break
                
                if not is_last_valid_item and entry['duration_ms'] > 0 : # Add silence only if current has duration and is not the last one with duration
                     running_time_ms += silence_duration_ms
                elif not is_last_valid_item and entry['duration_ms'] == 0 and silence_duration_ms > 0: # if item has 0 duration but silence is configured
                    # this means it's a placeholder, we might still add silence if it's not the absolute last item
                    # This logic can be tricky: if many 0-duration items, do we add silence after each?
                    # For now, only add silence after items that *had* audio or if explicitly handled.
                    # Simplified: add silence if not the last entry in the final list.
                    # Let's refine: Add silence if this item exists AND it's not the last *overall* item in the original list
                    # AND there's another valid item coming up or silence_duration > 0
                    # The previous check `is_last_valid_item` is better.
                     pass


            else: # Handle items that were not processed (e.g. original item was empty text and filtered out early)
                # If you need placeholders for these in the timecode list:
                # actual_timecodes_with_silence.append({
                #     'text': items[i].get('text', ''), 
                #     'original_index': i, 
                #     'duration_ms': 0, 
                #     'start_time_ms': round(running_time_ms), 
                #     'end_time_ms': round(running_time_ms),
                #     'error': 'item_skipped_or_empty'
                # })
                # If silence still needs to be added for consistency:
                # if i < original_items_count - 1 and silence_duration_ms > 0:
                #    running_time_ms += silence_duration_ms
                pass


        # 5. æ¸…ç†ä¸´æ—¶å”¯ä¸€éŸ³é¢‘æ–‡ä»¶
        paths_to_clean = [info['path'] for info in synthesized_unique_audios if info['path']]
        if paths_to_clean:
            print(f"ğŸ§¹ æ¸…ç† {len(paths_to_clean)} ä¸ªä¸´æ—¶å”¯ä¸€éŸ³é¢‘æ–‡ä»¶...")
            cleaned_count = 0
            for path in paths_to_clean:
                try:
                    if os.path.exists(path):
                        os.remove(path)
                        cleaned_count += 1
                except Exception as e:
                    print(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶ {path} å¤±è´¥: {e}")
            print(f"   => æˆåŠŸæ¸…ç† {cleaned_count} ä¸ªæ–‡ä»¶ã€‚")

        generation_time = time.time() - start_time
        
        return {
            'success': True,
            'timecodes': actual_timecodes_with_silence,
            'total_duration_with_silence_ms': round(running_time_ms),
            'items_processed_count': original_items_count,
            'unique_items_synthesized_count': items_to_synthesize_count, # Number of unique items we attempted to synthesize
            'actual_segments_with_audio_count': len([tc for tc in actual_timecodes_with_silence if tc['duration_ms'] > 0]),
            'silence_between_items_ms': silence_duration_ms,
            'generation_time_seconds': round(generation_time, 2),
            'processing_mode': processing_mode,
            'audio_format_generated': audio_format 
        }

    def _generate_item_key(self, item: Dict, default_rate: str, default_volume: str, default_pitch: str) -> str:
        """è¾…åŠ©æ–¹æ³•: ä¸ºTTS itemç”Ÿæˆä¸_deduplicate_itemsä¸­ä¸€è‡´çš„å”¯ä¸€é”®"""
        text = item.get('text', '').strip()
        
        # è·å–å½“å‰å¼•æ“çš„é»˜è®¤è¯­éŸ³æˆ–å…¨å±€é»˜è®¤è¯­éŸ³
        current_engine_config = self.engine_manager.get_current_engine().config if self.engine_manager.get_current_engine() else {}
        # TTS_CONFIG['default_voice'] ä½œä¸ºæœ€ç»ˆå¤‡é€‰
        default_voice_from_engine = current_engine_config.get('default_voice')
        if not default_voice_from_engine: # Fallback to global config if engine has no specific default
            default_voice_from_engine = TTS_CONFIG.get('default_voice', 'zh-CN-XiaoxiaoNeural') # Fallback to a hardcoded general default

        voice = item.get('voice', default_voice_from_engine)
        rate_val = item.get('rate', default_rate) 
        volume_val = item.get('volume', default_volume)
        pitch_val = item.get('pitch', default_pitch)
        return f"{text}|{voice}|{rate_val}|{volume_val}|{pitch_val}" 